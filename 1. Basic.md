# Cache
- SRAM expensive fast  
- 内存 DRAM

- 随机淘汰
- FIFO
- LRU（Last used）

# Storage
- Flash: SSD Hard Disk
- DVD/VCD
- Disk
- Tape

- Hardware
- Software:manage,snapshot,copy
- Network: HBA,Fiber Optic Switches,FC/SAS
- Centralized Storage, Archiving, Backup, Disaster Tolerant Backups

1. **Block Storage** bootable
- dividing data into **fixed-sized block**s and storing them on block devices such as h*ard drives* or *solid-state drives (SSDs)*. These blocks are accessed using *low-level block-level protocols*, typically through **storage area networks (SANs)** or d**irect-attached storage (DAS)**.
- **Low-level access**: Blocks can be read from or written directly, allowing for efficient and fast random access.
- Ideal for databases and transactional workloads: Block storage is commonly used for applications that require **low-latency, high-performance storage**, such as databases or virtual machines.
- Example
    - Amazon Elastic Block Store (EBS).
    - Azure Virtual Machines (VMs) can be used with the managed discs service for block volumes that Azure offers.
    - Google Cloud (Zonal persistent disk): Efficient and reliable block storage,
MNT mount point: 
    - directly mount to your virtual server VSI: can unmount it and mount it to a different server
    - mount to Hypervisor Layer
read only MNT mounted to many VSI 

2. **File Storage**
File storage stores data as files and presents it to its final users as a **hierarchical directories structure**. It is typically accessed using **file-level protocols** like *Network File System (NFS)* or *Server Message Block (SMB)*. File storage can be implemented using **network-attached storage** (NAS) devices or distributed file systems.
- Key features of file storage include:

    - **Shared access**: Multiple clients or systems can access and modify files concurrently, making them suitable for collaboration and shared file systems.
    - **File-level operations**: File storage provides operations at the file level, such as read, write, and modify, making it compatible with traditional file-based applications and workflows.
    - **Metadata support**: File systems often support metadata attributes associated with files, such as permissions, timestamps, and file attributes.

    - maintain the directory hierarchy in the same way that same as OS layer
    - MNTF
    - CAD files


3. **Object Storage**
- divided into **little parts** and dispersed over hardware in **a flat structure**. Instead of being maintained as *files in directories* or as *blocks on servers*, the data is divided up into **discrete parts called objects** and kept in **a single repository with object storage**. Object storage systems typically use a **RESTful API** for accessing and managing data.
- Key features of object storage include:
    - **Scalability and Durability**: Object storage is highly scalable and can handle *massive amounts of data*. It also provides built-in **redundancy and fault tolerance** for data durability.
    - **Flexible Metadata**: Each object can have custom metadata associated with it, enabling rich data management and search capabilities.
    - **Suitable for Unstructured Data**: Object storage is well-suited for storing and retrieving large amounts of unstructured data, such as media files, backups, or log files.






History:
1. 硬盘在server内部
2. 外部硬盘阵列DAS
3. 智能硬盘阵列DAS
4. 存储数据网络SAN(structured data) NAS

Protocol
1. SCSI: small computer system interface
2. FCI: fiber channer
3. iSCSI: internet small computer system interface
4. SAS: serial attached SCSI

- DAS(Direct Attached Storage) 1 controller 1 server
- **SAN(storage area network)** 1 controller many servers **blocks**
    - FC SAN : FC protocol, FC switch machine
    - IP SAN : IP network, Ethernet switch machine
    - A SAN is a dedicated high-speed **computer network** that provides block-level access to data storage. You can connect different storage devices to multiple servers. Some common uses of SANs include sharing data and improving the utilisation of storage systems. You can also use a SAN as a **centralised data management and backup system**. It improves the performance of storage-intensive applications, leading to reduced downtime and maintenance costs.
- NAS (network attached storage) **files**

# Hard Disk
1. Media
- **HDD** Hard Disk Drives (large RPM better)
    - non-volatile magnetic storage
    - random access, retrive data from any part of the drive any time
    - rotate to read data 连续读写性好(Video Surveillance)，随机读写性差(Database)
    - parts
        - spining platters, moving actuator arm
        - limit access speed
- **SSD** Solid State Drives 
    - very fast
    - non-volatile magnetic storage
    - store server system
    - no moving parts don't have Mainstream RPM (Revolutions per minute) read chips to read data
- **Flash memory**
    - EEPROM(Electrically erasble programmmable read only memory)
    - not designed for archival storage, easy to lose or damage
2. Disk Diameter
- 3.2 inch/2.5 inch
3. Interface
- ATA/IDE
- **SATA /mSATA(mini) / NL SAS**
    - Tolerant Backups
- SCSI
- **SAS**
    - server data
- FC  
* SATA designed for hard drives
    - use AHCI(Advanced Host Controller Interface) to move data to RAM
    - 3 throughput 600MB/s
    - SSD need a faster method
- **M.2** interface
    - most **NVMe(Non-volatile Memory Express)** throughput
    - designed for SSD speeds
    - lower latency, much higher throughputs
    - connector types: B key SSD, M key SSD
4. Performance
- Volume
- Rotate speed
- Average access time
- Data Transfer Rate
- Input/Output Per Second(IOPS)


# PCI Express
**high-speed serial computer expansion bus standard**  

Every desktop PC motherboard has a number of PCIe slots you can use to add various components such as GPUs (also known as video cards or graphics cards), RAID cards, Wi-Fi cards, or SSD (solid-state drive) add-on cards².    

The types of **PCIe slots** available in your PC will depend on the motherboard you buy. PCIe slots come in different physical configurations: x1, x4, x8, x16, x32. The number after the 'x' tells you **how many lanes (how data travels to and from the PCIe card) that PCIe slot has**².   

For example, *a PCIe x1 slot has one lane and can move data at one bit per cycle*. A PCIe x2 slot has two lanes and can move data at two bits per cycle, and so on². 

# RDMA
**Remote Direct Memory Access** (RDMA) is a technology that allows one computer to access the memory of another computer without involving the operating system, processor, or cache of either computer¹². This results in **high-throughput and low-latency** networking, which is particularly useful in **massively parallel computer clusters**¹.

RDMA supports zero-copy networking by enabling the **network adapter** to transfer data directly from the **wire to application memory**, or vice versa, eliminating the need to copy data between application memory and the data buffers in the operating system¹. This reduces latency in message transfer¹.

RDMA can transport data reliably or unreliably over the Reliably Connected (RC) and Unreliable Datagram (UD) transport protocols, respectively¹. Common **RDMA implementations** include the Virtual Interface Architecture, **RDMA over Converged Ethernet (RoCE)**, InfiniBand, Omni-Path, and iWARP¹.

Applications perform RDMA operations by submitting work queue entries (WQEs) into the submission queue (SQ) and getting notified of responses from the completion queue (CQ)¹.


# CXL
Compute Express Link (CXL) is a high-speed CPU interconnect that enables efficient sharing of memory across devices¹². Here are some key points about CXL and memory management:

1. **Memory Pooling and Sharing**: CXL allows for both shared and pooled memory to serve different purposes¹. Shared memory is a type of memory that can be accessed by multiple devices, while pooled memory refers to a collection of memory resources that can be dynamically allocated and deallocated¹.

2. **Memory Lakes**: As datasets grow from megabytes to terabytes to petabytes, the cost of moving data from the block storage devices across interconnects into system memory, performing computation, and then storing the large dataset back to persistent storage is rising in terms of time and power². CXL addresses this problem by keeping the datasets in large, byte-addressable, sharable memory².

3. **CXL 3.1 Standard**: The new CXL 3.1 standard allows for byte-addressable, load-store-accessible memory like DRAM to be shared between different hosts over a low-latency, high-bandwidth interface using industry-standard components².

4. **Zero-Copy Memory**: CXL shared memory allows for zero-copy networking, which means the network adapter can transfer data directly from the wire to application memory, or vice versa, eliminating the need to copy data between application memory and the data buffers in the operating system².

5. **Memory Lake Concept**: A memory lake takes advantage of the new features of the CXL 3.1 specification and adds the capabilities discussed above and more².
